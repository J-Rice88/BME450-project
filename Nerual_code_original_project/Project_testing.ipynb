{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = scipy.io.loadmat('sorted_zWF_data.mat')\n",
    "waves = total['zWF']\n",
    "sorted = total['sorted']\n",
    "\n",
    "waves = torch.tensor(waves)\n",
    "sorted = torch.tensor(sorted)\n",
    "class_indices = torch.argmax(sorted, dim=0)\n",
    "\n",
    "# Create a list to hold tuples\n",
    "data = []\n",
    "\n",
    "# Generate data for each index\n",
    "for i in range(len(waves)):\n",
    "    for k in range(len(waves.T)):\n",
    "        waves[i,k] = waves[i,k].to(torch.float32)\n",
    "    vector = waves[i,:] # Generating a random vector of length 31\n",
    "    integer = class_indices[i]  # Generating a random integer\n",
    "    data.append(((vector), (integer)))\n",
    "\n",
    "split_index = int(len(data) * 0.8)\n",
    "\n",
    "# Split the variable list\n",
    "train_data = data[:split_index]\n",
    "test_data = data[split_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #self.flatten = nn.Flatten()\n",
    "        self.l1 = nn.Linear(len(waves.T), 50)\n",
    "        #self.l2 = nn.Linear(50, 50)\n",
    "        #self.l3 = nn.Linear(50,20)\n",
    "        self.l4 = nn.Linear(50,3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.flatten(x)\n",
    "        x = F.relu(self.l1(x))\n",
    "        #x = F.relu(self.l2(x))\n",
    "        #x = F.relu(self.l3(x))\n",
    "        output = self.l4(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "model = Net()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(torch.float32)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(torch.float32)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HELP FROM CHATGPT\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        vector, integer = self.data[index]\n",
    "        return vector, integer\n",
    "\n",
    "# Assuming you have created train_data and test_data\n",
    "# Create datasets for both parts\n",
    "train_dataset = CustomDataset(train_data)\n",
    "test_dataset = CustomDataset(test_data)\n",
    "\n",
    "# Create data loaders for both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.067462  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.618814 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.600808  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.377692 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.364596  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.253370 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.253772  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.178095 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.189483  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.134834 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.143058  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.104425 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.105211  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.085208 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.084107  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.069798 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.068429  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.060114 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.060237  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.051724 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.052033  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045505 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.049449  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.040991 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.045554  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.036572 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.038074  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033750 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.030425  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030551 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.029579  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028608 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.025048  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026141 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.028816  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024536 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.020977  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023172 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.020112  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021747 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.024391  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020559 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.015943  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019302 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.017503  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018287 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.017822  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017407 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.015988  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016729 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.012947  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016113 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.013937  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017154 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.012449  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014639 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.013142  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014260 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.013950  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013751 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.011548  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013070 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.013845  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012676 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.010631  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012284 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.010219  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011908 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.010022  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011505 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.008956  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011274 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.014957  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010882 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.008559  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010632 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.007652  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010389 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.011260  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010011 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.008921  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009824 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.006352  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009590 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.008096  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009333 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.009010  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009108 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.012283  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008853 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.005892  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008687 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.008654  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008611 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.006939  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008329 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.009397  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008245 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.004675  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008122 \n",
      "\n",
      "Done!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.006418  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007924 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.006732  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007686 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.006467  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007511 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.007203  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007462 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.005022  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007359 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.004207  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007264 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.006743  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007001 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.005693  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006893 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.005669  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006862 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.004011  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006725 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.004423  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006556 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.009682  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006520 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.006885  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006512 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.008019  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006258 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.006740  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006252 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.003594  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006145 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.006050  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006050 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.004500  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005954 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.012641  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005865 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.006302  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006366 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.008782  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005724 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.003806  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005661 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.004490  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005541 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.005070  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005540 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.004508  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006170 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.003908  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005360 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.002828  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005345 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.003108  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005216 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.005475  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005154 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.003564  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005065 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.004059  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.005026 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.002323  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004992 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.005131  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004910 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.003653  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004875 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.007075  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004797 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.002886  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004750 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.004639  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004942 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.005491  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004639 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.008537  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004609 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.004727  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004565 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.003552  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004504 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.003067  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004489 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.004128  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004488 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.007146  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004477 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.001999  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004338 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.004730  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004390 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.006591  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004278 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.002457  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004224 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.002401  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004350 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.004610  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004167 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.002840  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004101 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.002190  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004069 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.006625  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.004036 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.006592  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003994 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.003514  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003958 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.001989  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003971 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.001928  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003954 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.002316  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003871 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.001920  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003836 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.002363  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003811 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.002151  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003777 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.002345  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003758 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.003790  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003696 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.002735  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003690 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.006306  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003683 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.003163  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003654 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.002388  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003592 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.003241  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003585 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.002236  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003566 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.002224  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003507 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.002339  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003498 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.002095  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003482 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.002988  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003452 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.001228  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003408 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.002460  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003381 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.001712  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003363 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.002621  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003349 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.004704  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003333 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.001555  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003323 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.003330  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003268 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.003073  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003249 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.001759  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003225 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.001464  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003236 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.002005  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003200 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.003098  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003161 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.001928  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003167 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.001387  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003138 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.002219  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003164 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.001509  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003069 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.001992  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003038 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.001193  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003050 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.002973  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003014 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.002695  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002997 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.001955  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003051 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.001102  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002956 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.003709  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002974 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.003991  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003209 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.001333  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002925 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.003605  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002902 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.002424  [   64/  705]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002880 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(test_dataset, batch_size=64, shuffle= True)\n",
    "test_dataloader = DataLoader(train_dataset, batch_size=64, shuffle= True)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "batch_size = 64\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "\n",
    "learning_rate = 1e-4\n",
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m sample_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;66;03m# select a random sample\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m[sample_num][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;28;01mNone\u001b[39;00m,:,:,:]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "sample_num = 4 # select a random sample\n",
    "x = test[sample_num][0]\n",
    "x = x[None,:,:,:]\n",
    "with torch.no_grad():\n",
    "   r = model(x)\n",
    "print('neural network output pseudo-probabilities:', r)\n",
    "print('neural network output class number:', torch.argmax(r).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
